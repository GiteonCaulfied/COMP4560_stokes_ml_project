\chapter{Concluding Remarks}\label{chap:conclusion}

\section{Conclusion}

In this research, we use Neural Networks (NN) to approximate the solution of the forward modelling problem of geoid as a set of spherical harmonic coefficients given a 1D spherically symmetric viscosity model. The dataset used to train the algorithms consists of 1,000 pairs of the above models and has a reduced prior such that the perturbations to the output are smaller to simplify the problem. The dataset is fed into different feed-forward Fully Connected Neural Network (FNN) architectures with different sets of hyperparameters to systematically find the model with the best performance. 

We found that FNN architectures with a total of 3-4 hidden layers have the best mean accuracy. This could be presented as a proof showing that high-dimensional regression algorithms like neural networks can help with the forward modelling of the geoid problem when predicting a set of spherical harmonic coefficients given a reduced dataset with a fairly small number of 1D spherically symmetric viscosity models.

As for the 2D mantle convection Problem, we use NN as a surrogate model for mantle convection simulations. The three datasets used to train the algorithms comes from either 100 or 903 mantle convection simulations of the Earth or is interpolated using the above dataset. For each of the datasets, we first compress the temperature fields by a factor of 13 using a Convolutional AutoEncoder, and then tested two neural network algorithms for predicting the compressed temperature fields at the next time step given previous temperature fields. 

We found that while the feed-forward Fully Connected Neural Network (FNN) offers a better accuracy and the result has less data loss when "One-for-One" is used to predict a complete time series, the Long short-term memory (LSTM) is slightly more capable to capture the general patterns of a complete simulation compared with the "One-for-All" method when predicting a time series via FNN. We also found that datasets with varying time distance between temperature fields could lead to the problem of the predicted temperature time series being convected faster or slower than the ground truth, and we addressed this issue by using an interpolated dataset that has the same time distance between temperature fields.

We have tested two possible methods for FNN to predict a complete simulation, one of them ("One-for-All") only takes an initial temperature field and feeds it in an output-as-input loop to get the prediction at each time step, while the other one ("One-for-One") just uses the ground truth from the simulator at the previous time step as the input to the FNN. The former method clearly consumes much less computation resources (1:99 of the demanding ground truth from numerical simulator when comparing these two method) but suffers from low accuracy.

Therefore, to determine experimentally for how many time steps we can use the trained FNN during a set of $S$ consecutive time steps before we correct it using the ground truth from the simulator, further experiments are conducted on the FNN trained with an interpolated dataset. And we found that the growth of the data loss with $S$ (ranging from 1, 2, 4, 8 to 16) is remarkably moderate (less than $O(S)$), with only a few outliers deviating moderately from the median. This could provide some avenues for future research.

\section{Future Work}

For the geoid problem, future work may focus on extending the current study to a more general dataset. The one used in this research is generated using a reduced prior such that the perturbations to the output are relatively smaller. Also, there could be more exploration on the potential use of neural networks to backward model the geoid problem, since the fact that the geoid problem is well predicted by a FNN suggests that this avenue of research would be fruitful.

As for the 2D mantle convection problem, future studies may continue to explore the potential use of the trained FNN on a set of $S$ consecutive time steps. If we can replace the fine-grained truth temperature field from the simulator (size is $201 \times 401$), which is used to "correct" the predicted time series, with a coarse-grained temperature field (e.g. size is $50 \times 100$) instead, the computational demands of modelling mantle convection problem could be further reduced.

Future studies could also focus on improving the performance of LSTM, using less truth temperature fields to predict more temperature fields (20:80) or using less truth temperature fields to predict less temperature fields (20:20), rather than sticking to the current ratio of 50:50 for input and output due to the technical limitations of PyTorch with LSTMs.

Other studies could include the outliers in in Figure \ref{figure:further_loss_Box} to see whether a common pattern can be identified. Also, more complex physics (e.g., non-linear constitutive laws) could be considered in the Mantle convection model that was used as the basis for the datasets generation. Apart from these, being able to design ML solution which are able to deal with the additional trouble caused by adaptive time stepping would also be a useful avenue of future research.

Investigating to which extent the current surrogate forward models are accurate enough to end up with sensible, application experts-certified solutions to the inverse mantle convection problem is also a potential matter for future research, supported by our further evaluation of the FNN trained with an interpolated dataset.