\chapter{Concluding Remarks}\label{chap:conclusion}

\section{Conclusion}

In this research, we use Neural Networks (NN) to solve the forward modelling problem of geoid as a set of spherical harmonic coefficients given a 1D spherically symmetric viscosity model. The dataset used to train the algorithms consists of 1000 pairs of the above models and has a reduced prior such that the perturbations to the output are smaller to simplify the problem. The dataset is fed into different feed-forward Fully Connected Neural Network (FNN) architectures with different set of hyperparameters systematically to find the model with the best performance. 

We found that FNN architectures with a total of 3â€“4 hidden layers have the best mean accuracy. This could presented as a proof showing that high-dimensional regression algorithms like neural networks can help with the forward modelling of the geoid problem when predicting a set of spherical harmonic coefficients given a reduced dataset with a fairly small number of 1D spherically symmetric viscosity models.

As for the Mantle Convection Problem, we use NN as a surrogate model for mantle convection simulations. The three datasets used to train the algorithms comes from either 100 or 903 mantle convection simulations of the Earth or is interpolated using the above dataset. For each of the dataset, We first compress the temperature fields using a Convolutional AutoEncoder by a factor of 13, and then tested two neural network algorithms for predicting the compressed temperature fields at the next time step given previous temperature fields. 

We found that while the feed-forward Fully Connected Neural Network (FNN) offers a better accuracy and the result has less data loss when "One-for-One" is used to predict a complete time series, the Long short-term memory (LSTM) is slightly more capable to capture the general characteristics of a complete simulation compared with the "One-for-All" method when predicting a sequence using FNN. We also found that dataset with adaptive time steps between each temperature field could lead to the problem of the predicted time series moving faster or slower than the ground truth, and we solved this issue by using an interpolated dataset that having the same distance between temperature fields.

We have tested two possible methods for FNN to predict a complete simulation, one of them ("One-for-All") only takes an initial temperature field and feeds it in an output-as-input loop to get the prediction at each time steps, while the other one ("One-for-One") just use the ground truth at the previous time step from the simulator when FNN tries to make predictions. The former method clearly use much less computation resources (1:99 of the demanding ground truth from numerical simulator when comparing these two method) but suffers from low accuracy.

Therefore, to determine experimentally for how many time steps we can use the trained FNN during a set of S consecutive time steps before we correct it using the ground truth from the simulator, further testings are conducted on the FNN trained with an interpolated dataset. And we found that the growth of the data loss with S (ranging from 1, 2, 4, 8 to 16) is remarkably moderate (less than $O(S)$), with only a few outliers deviating moderately from the median. This could provide some avenues for the future research.

\section{Future Work}

For the geoid problem, future studies may focus on extending the use of neural networks on solving the geoid problem using viscosity models by testing with a more general dataset, since the one used in this research is using a reduced prior such that the perturbations to the output are relatively smaller. Also, there could be more exploration on the potential use of neural networks to backward model the geoid problem, since the fact that the geoid problem is well predicted by a FNN suggests that this avenue of research would be fruitful.

As for the mantle convection problem, future studies may continue to explore the potential use of the trained FNN on a set of S consecutive time steps. If we can somehow replace the fine-grained truth temperature field from the simulator (size is $201 \times 401$), which is used to "correct" the predicted time series, with a coarse-grained temperature field (e.g. size is $50 \times 100$) instead, the computational demands of modelling mantle convection problem could be further reduced.

Future studies could also focus on improving the performance of LSTM, using less truth temperature fields to predict more temperature fields (20:80) or using less truth temperature fields to predict less temperature fields (20:20), rather than sticking to the current ratio of 50:50 for input and output due to technical limitations of PyTorch.

Other studies could include further investigations on the outliers in the Box Plot of the Data loss when FNN is used in S consecutive time steps in Figure \ref{figure:further_loss_Box} to see whether a common pattern can be identified. Also, more complex physics (e.g., non-linear constitutive laws) could be considered in building Mantle convection model for testing. Apart from these, somehow accounting for adaptive time steps used within the NN would also be a useful avenue of research.

Investigating to which extent the current surrogate forward models are accurate enough to end up with sensible, application experts-certified solutions to the inverse Mantle Convection problem is also beneficial for the future research, supported by our further testings on FNN trained with an interpolated dataset.