\chapter{Mantle Convection Simulation}\label{chap:evaluation}

\section{Mantle Convection Simulation on Limited Dataset}

The limited data set consists of 100 files and each of them represents one mantle convection simulation in 100 time steps generated with an initial condition with random number of points and random amplitude and coordinates of Gaussian anomalies distributed in space (a total of 10000 temperature fields). Starting from each initial condition we convect as long as there is meaningful change in the simulation (that is the temperature fields change enough after one time-step). There are 100 temperature fields with a size of $201 \times 401$ for each of the 100 timestamps in a file and the time step has to be adaptive, otherwise the whole random generation of the initial condition would be hard to implement. This adaptive timestamps lead to a problem, that is, the distance between each consecutive time steps are not the same even in the same simulation file. This could lead to some uncommon behaviors when predicting a sequence of temperature fields using the ML architecture, which will be discussed in more details in the following sections.

The following figure shows one random temperature fields in the data set with the y-axis inverted and colored using 10-color-map (all the figures in this chapter will have their y-axis inverted and colored using 10-color-map as well, but without labels on x-axis and y-axis for better visualisation):

\begin{figure}[H]
    \caption{Temperature Field example}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/temperature_field_example.png}
\end{figure}

The entire data set is still randomly divided in a ratio of 8:1:1: 80 per cent of the data set is used for training, 10 per cent of the data for testing and the remaining 10 per cent to perform validation. However, the way we divide them is different in implementing the ConvAE, FNN and LSTM and will be discussed in more details in the following sections.

The data set is uploaded to Gadi, a HPC system, for storage to make the training process more efficient. 

\subsection{Compression of temperature fields}

Since applying Machine Learning (ML) algorithms directly on the original sized temperature fields can take significantly more time to train the model and could possibly lead to the risk of over-parameterization, we decided to compress the temperature fields first before feed the data into different ML architectures.

In this study, the overall process to solve the mantle convection problem woule be: 

\begin{enumerate}
  \item Train the ConvAE
  \item Train the FNN/LSTM using the latent space representation for both input and output data (using encoder from ConvAE)
  \item Test the prediction result in original size (using decoder from ConvAE)
\end{enumerate}

The complete 10000 temperature fields are randomly shuffled and divided in a ratio of 80\%, 10\%, 10\% for training, testing and validation where each piece of data consists only one temperature field (fed as both the input and output). Given the size of the training set, ConvAE is fed with a batch size of 16 temperature fields during the training to perform Mini-Batch Gradient Descent.

We find that ConvAE with a latent space size of $5 \times 23 \times 45$ offers an excellent compression factor of 13, while being able to reconstruct the temperature fields in original size with the lowest data loss on the test set.

The architecture of the ConvAE in this case consists of two convolutional layers for the encoder and two transpose convolutional layers for the decoder. Both of these four layers have the size of the filter as $5 \times 5$ and a stride of $3 \times 3$. Tanh() is used as activation function to introduce non-linearity between each layers (except for the last layer in the decoder) and mean square error (MSE) is used as the loss function. The model is trained for 1000 epochs on Gadi.

In the following figures, we present some detailed test results from this ConvAE:

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/limited_dataset/ConvAE_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/limited_dataset/ConvAE_OverallTesting.png}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/mantle_convection_images/limited_dataset/ConvAE_Best.png}
    \caption{Best Case}
    \label{fig:first}
\end{subfigure}
\hfill
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/mantle_convection_images/limited_dataset/ConvAE_Worst.png}
    \caption{Worst Case}
    \label{fig:second}
\end{subfigure}
        
\caption{Best case and worst case using ConvAE}
\label{fig:figures}
\end{figure}


On average, the reconstruction loss are low and no overfitting occurs. However, we can observe that the ConvAE does not reconstructe the thin feature in the bottom right corner of the worst case. This could imply that the ConvAE works best for "smooth" input hence others with small scale length features will generally perform worse.

We also applied some POD (Proper Orthogonal Decomposition) analysis to the compressed-decompressed fields with contrast to the original temperature fields and the result is great as well, the figure to this analysis will be presented in the following sections as contrast to the POD analysis of the prediction model (FNN or LSTM) 


\subsection{Fully Connected Neural Network (FNN) for Prediction}

We now move on to predict the latent space representation and the first candidate is FNN. The FNN in this study uses each adjacent pair of temperature fields (e.g. $i$th and ($i+1$)th fields) as one training set, takes one temperature fields as the input and output the temperature fields at the next time step. Therefore, the data set is reconstructed into 9900 pairs of temperature fields with consecutive timestamps. These pairs are randomly shuffled and divided in a ratio of 80\%, 10\%, 10\% for training, testing and validation where each piece of data consists two temperature field having consecutive timestamps.

Before the latent space representation is fed as the input of FNN, it is flattened into one dimension. The prediction of FNN in this case is then resized from a one dimensional vector ($1 \times 6210$) to the shape of the latent space ($6 \times 23 \times 45$) for the convenience of further testing.

The learnable parameters of FNN are optimized using small mini-batches of 16 pairs of consecutive temperature fields and Adam as the optimizer, where the loss function is defined as the mean square error (MSE) between the prediction of FNN and the actual output (both in the shape of latent space representation, which is $6 \times 23 \times 45$).

After testing with FNNs with architectures of different number of hidden layers and neurons per hidden layer, we found that architectures with a total number 3 hidden layers seemed to perform the best. (We also test some deeper architectures with 4-5 hidden layers. However, there is no significant improvement in loss value)

In the following figures, we present results from a FNN with 3 hidden layers with 3105, 1035, 3105 and 80 neurons, Tanh() as activation function, and trained for 1000 epochs.

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/limited_dataset/FNN_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/limited_dataset/FNN_OverallTesting.png}
\end{figure}

\begin{figure}[H]
    \caption{Best case original output, original output after ConvAE's compression-decompression, and predicted output of FNN}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/limited_dataset/FNN_Best.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case original output, original output after ConvAE's compression-decompression, and predicted output of FNN}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/limited_dataset/FNN_Worst.png}
\end{figure}

On average, the loss values are low and no overfitting occurs. The prediction for the temperature field at the next timestamp is able to capture the main features precisely with some small information loss, which is partially due to information loss caused by the compression-decompression process of ConvAE.

To further evaluate the performance of FNN in predicting a complete time series, two methods are tested on all 100 files one by one: 

\begin{enumerate}
  \item Only take the first temperature field in the file as the input and use a prediction-as-input loop to get the rest of the 99 temperature fields. (use $T1$ from data set $\rightarrow$ get predicted $T2$ $\rightarrow$ use predicted $T2$ $\rightarrow$ get predicted $T3$ $\rightarrow$ ...)
  \item Constantly feed a temperature field from the original data set and get the temperature field at the next time step as usual. (use $T1$ from data set $\rightarrow$ get predicted $T2$ $\rightarrow$ use $T2$ from data set $\rightarrow$ get predicted $T3$ $\rightarrow$ ...)
\end{enumerate}

In this case, the first method can reduce the computation complexity of the mantle convection problem more effectively than the second method, since we only need one initial input data and the model can generate the rest of the temperature field sequence. Therefore, the following best case and worst case will be evaluated using the data loss of the first method.

To better visualize the prediction result of the above two methods, two animations representing the best case and the worst case (evaluated based on the sum of MSE for each prediction using the first method) in the format of GIF files are generated. From top to bottom, the first picture represents the actual output from the data set, the second one represents the prediction result using the first method, and the last one represents the prediction result using the second method.

The following figures show 10\% of the sprites sheets converted from the original GIFs (Every 10th frame) for the convenience of reading:

\begin{figure}[H]
    \centering
    \caption{Best case animation sheet (Link to this GIF: \url{https://drive.google.com/file/d/1Hmb4UlevBHMRw0jDScTwUzDFPbYNubKO/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/limited_dataset/FNN_Best_GIF_sheet.png}
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Worst case animation sheet (Link to this GIF: 
    \url{https://drive.google.com/file/d/11jRFxq-XuIUvTk74OuxswDn3u031k_q7/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/limited_dataset/FNN_Worst_GIF_sheet.png}
\end{figure}

To further evaluate the performance of these two methods, we also applied a technique called Proper Orthogonal Decomposition (POD) to the set of predictions generated by these two methods in both the best case and the worst case, along with the original time series and the compressed-decompressed version generated by ConvAE serve as contrast.

POD is mainly used to decompose a physical field (e.g. temperature field) depending on the different variables that influence its physical behaviors and it is similar to Principle Component Analysis (PCA) since it refers to eigenvalues of a physical field.\citep{10.1146_annurev.fl.25.010193.002543} Following \citep{10.1515_9783110671490-007}, the Singular Value Decomposition (SVD) of a simulation matrix $X$ (spatial points Ã— time-steps, in this case it's $201 \times 401 \times 100$) is computed as:

\begin{equation}
X = U\Sigma V
\end{equation}

where the diagonal of $\Sigma$ contains the eigenvalues (POD coefficient) for this simulation.

The following figures show the POD result in the best case and the worst case:

\begin{figure}[H]
    \caption{Best case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/limited_dataset/FNN_Best_POD.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/limited_dataset/FNN_Worst_POD.png}
\end{figure}

As seen in the animations and the POD results, the first method (output-as-input prediction) fails to capture the trend of the temperature fields simulations in the worst case and the result prediction is completely different to the actual simulations. This is because the information loss from the ConvAE and FNN in each prediction-as-input loop accumulates, leading to poor result after 99 iterations. In the mean time, the prediction result for the second method mostly matches with the actual output in both cases, which is consistent to our theory that the it is the first method itself leads to the huge information loss.

Also, the predicted GIFs in this case are either moving faster or slower than the actual simulations. This is probably due to the varying distance between time steps in the simulation. In this case, the model will try to predict the temperature field at the next time step by averaging out the distance between each time step, thus making the predicted simulations either too fast or too slow.

To explore if we can generate a sequence of temperature fields with less information loss, we try to use LSTM to predict the latent space representation instead.


\subsection{Long short-term memory (LSTM) for Prediction}

We now move on to predict a sequence of latent space representation using LSTM. The LSTM in this study uses the first 50 temperature fields as a sequence in each file as one training set, takes a sequence of 50 temperature fields as the input and output the rest 50 temperature fields at the next time steps.

This 50:50 of input-output length is determined by PyTorch's limitation on LSTM, where the input length and the output length should be the same for the LSTM to functionally work. A ratio of less input length and more output length (20:80) has been considered, but this requires the input sequence to be replicated into 4 times the size to match with PyTorch's requirement, which could lead to worse prediction result compared with the 50:50 ratio.

Therefore, the files in the data set are randomly shuffled and divided in a ratio of 80\%, 10\%, 10\% for training, testing and validation where each piece of data is a complete file to be divided in half as input and output.

Again, before a sequence of latent space representation is fed as the input of LSTM, it is flattened into two dimension with its sequence index reserved ($50 \times 6210$). The prediction of LSTM in this case is then resized from $50 \times 6210$ to $50 \times 6 \times 23 \times 45$ for the convenience of further testing.

The learnable parameters of LSTM are optimized using small mini-batches (only 1 batch in this case since we merely have 80 training samples) and Adam as the optimizer, where the loss function is defined as the MSE between the prediction of LSTM and the actual output (both in the shape of a sequence of latent space representation, which is $50 \times 6 \times 23 \times 45$).

After testing with LSTMs with different architectures, we found that architectures with a total number of 2 consecutive LSTMs layers seemed to perform the best. (We also test some deeper architectures with 4-6 LSTM. However, there is no significant improvement in loss value)

In the following figures, we present results from an architecture with 2 LSTM layers (first one input size is 6210, hidden size is 3105; second one input size is 3105, hidden size is 6210. Both of them only have one layer, no internal stacking), and trained for 200 epochs.

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/limited_dataset/LSTM_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/limited_dataset/LSTM_OverallTesting.png}
\end{figure}

\begin{figure}[H]
    \caption{Best case original output, original output after ConvAE's compression-decompression, and predicted output of LSTM}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/limited_dataset/LSTM_Best.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case original output, original output after ConvAE's compression-decompression, and predicted output of LSTM}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/limited_dataset/LSTM_Worst.png}
\end{figure}

On average, the loss values are higher than the FNN and no overfitting occurs. The prediction for the temperature field at the next timestamp is able to capture the main features precisely with some small information loss in the best case, but fails to do so in the worst case. This is caused by the internal structure of LSTM since the worst case is the first temperature field in the output sequence.

To better visualize the prediction result of LSTM on a 50:50 input length to output length ratio, two animations representing the best case and the worst case (evaluated based on the sum of MSE for each predicted temperature in the output sequence) in the format of GIF files are generated. From top to bottom, the first picture represents the actual output from the data set and the second one represents the prediction result.

The following figures show 20\% of the sprites sheets converted from the original GIFs (Every 5th frame) for the convenience of reading:

\begin{figure}[H]
    \centering
    \caption{Best case animation sheet (Link to this GIF: \url{https://drive.google.com/file/d/1zNJrZUB8XBAEWsUHPd2NANuWkE8yNg3z/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/limited_dataset/LSTM_Best_GIF_sheet.png}
\end{figure}



\begin{figure}[H]
    \centering
    \caption{Worst case animation sheet, (Link to this GIF: 
    \url{https://drive.google.com/file/d/1nINRk2Oh8rgQBLWio_b6R6I7T18e7Zi-/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/limited_dataset/LSTM_Worst_GIF_sheet.png}
\end{figure}

To further evaluate the performance, we also applied POD to a sequence of predictions generated by LSTM in both the best case and the worst case, with the original time series and the compressed-decompressed version generated by ConvAE serving as contrast.

The following figures show the POD result in best case and the worst case:

\begin{figure}[H]
    \caption{Best case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/limited_dataset/LSTM_Best_POD.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/limited_dataset/LSTM_Worst_POD.png}
\end{figure}

From the animations and the POD results, we can conclude that LSTM is able to capture the characteristics of the simulations even in its worst case. However, the simulations predicted using LSTM are less accurate and have more data loss compared with those predicted using FNN. There could be potential underfitting problem due to the lack of training data since only 80 samples are used for training.


\section{Mantle Convection Simulation on Larger Dataset}

To confirm if the low accuracy of LSTM is caused by the scarceness of data, a larger data set is tested, whose only two differences with the limited data set are that it now contains 903 simulations and it uses absolute time steps instead of adaptive time steps. However, even though it now uses absolute time steps instead, the distance between each of the consecutive time steps still varies.

For this section, time steps are not considered since we want to mainly focus on testing if the scarceness of data is the reason for the low accuracy of LSTM. Nevertheless, they will be used in the next section to create an interpolated data set.

The larger dataset are randomly divided in the same way as the limited dataset for each of the three ML architectures in the following subsections.

\subsection{Compression of temperature fields}

The ConvAE used for compressing the temperature fields in this section has the same structure and the same set of hyperparamters as the one trained with limited dataset, except that the total number of epochs are now reduced from 1000 to 200 due to the constrains of the computation resources on Gadi.

In the following figures, some detailed test results from this ConvAE trained with larger dataset are presented:

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/larger_dataset/ConvAE_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/larger_dataset/ConvAE_OverallTesting.png}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/mantle_convection_images/larger_dataset/ConvAE_Best.png}
    \caption{Best Case}
    \label{fig:first}
\end{subfigure}
\hfill
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/mantle_convection_images/larger_dataset/ConvAE_Worst.png}
    \caption{Worst Case}
    \label{fig:second}
\end{subfigure}
        
\caption{Best case and worst case using ConvAE}
\label{fig:figures}
\end{figure}

Overall, the performance of this ConvAE is similar to the one trained with limited dataset: reconstruction loss are low and no overfitting occurs.


\subsection{Fully Connected Neural Network (FNN) for Prediction}

The FNN in this section also has the same structure and the same set of hyperparamters as the one trained with limited dataset, except that the total number of epochs are reduced from 1000 to 200 as well.

The results are presented in the following figures:

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/larger_dataset/FNN_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/larger_dataset/FNN_OverallTesting.png}
\end{figure}

\begin{figure}[H]
    \caption{Best case original output, original output after ConvAE's compression-decompression, and predicted output of FNN}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset/FNN_Best.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case original output, original output after ConvAE's compression-decompression, and predicted output of FNN}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset/FNN_Worst.png}
\end{figure}

The above result of this FNN are similar to the one trained with limited dataset: the loss values are low and no overfitting occurs. There are still some small information loss, which is now confirmed as caused by the loss of data generated during the compression-decompression process of ConvAE.

Again, two animations representing the best case and the worst case when predicting the entire simulation using the first method (use $T1$ from data set $\rightarrow$ get predicted $T2$ $\rightarrow$ use predicted $T2$ $\rightarrow$ get predicted $T3$ $\rightarrow$ ...) are generated.

The following figures show 10\% of the sprites sheets converted from the original GIF animations (Every 10th frame), along with the POD result for the best case and worst case:

\begin{figure}[H]
    \centering
    \caption{Best case animation sheet (Link to this GIF: \url{https://drive.google.com/file/d/1LxuwXxEoG5xsYzLYn6n6-mUfoP8A3IC2/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/larger_dataset/FNN_Best_GIF_sheet.png}
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Worst case animation sheet (Link to this GIF: 
    \url{https://drive.google.com/file/d/1vwfL_n6ANnkJEY3B8a024SF_yQ35Hkxu/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/larger_dataset/FNN_Worst_GIF_sheet.png}
\end{figure}


\begin{figure}[H]
    \caption{Best case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset/FNN_Best_POD.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset/FNN_Worst_POD.png}
\end{figure}

We can observe that the increasing size of the training data does not improve the quality of the animations when predicting the entire simulations using the first method. Also, apart from the huge information loss, the problem of the predicted GIFs moving too fast or too slow still exists.


\subsection{Long short-term memory (LSTM) for Prediction}

The LSTM in this section also has the same structure and the same set of hyperparamters as the one trained with limited dataset, except that the total number of epochs are reduced from 200 to 100.

The results are presented in the following figures:

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/larger_dataset/LSTM_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/larger_dataset/LSTM_OverallTesting.png}
\end{figure}

\begin{figure}[H]
    \caption{Best case original output, original output after ConvAE's compression-decompression, and predicted output of LSTM}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset/LSTM_Best.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case original output, original output after ConvAE's compression-decompression, and predicted output of LSTM}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset/LSTM_Worst.png}
\end{figure}


From the above figures, we can see that the loss of the best case and the worst case for this LSTM are in the same level as the one trained with limited dataset given 10 times of the training data, which means that the low accuracy of LSTM is not caused by some potential underfitting problem as discussed in the last section.

For better visualisation as well, two animations representing the best case and the worst case when predicting the rest of the simulation using the first 50 temperature fields are generated.

The following figures show 20\% of the sprites sheets converted from the original GIF animations (Every 5th frame), along with the POD result for the best case and worst case:

\begin{figure}[H]
    \centering
    \caption{Best case animation sheet (Link to this GIF: \url{https://drive.google.com/file/d/1UFYSPVLT1wRsKM5GAdCz0JQLZF8OKNUc/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/larger_dataset/LSTM_Best_GIF_sheet.png}
\end{figure}



\begin{figure}[H]
    \centering
    \caption{Worst case animation sheet, (Link to this GIF: 
    \url{https://drive.google.com/file/d/1SbzjPwwe7FCu7JCJru8UYHOu9j6uVfZd/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/larger_dataset/LSTM_Worst_GIF_sheet.png}
\end{figure}


\begin{figure}[H]
    \caption{Best case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset/LSTM_Best_POD.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset/LSTM_Worst_POD.png}
\end{figure}

From the animations and the POD results, we can now confirmed that LSTM is able to capture most of characteristics of the simulations even in its worst case and the simulations predicted using LSTM are less accurate compared with those predicted using FNN.


\section{Mantle Convection Simulation on Interpolated Dataset}

To confirm if the problem of the predicted GIFs moving too fast or too slow is caused by the varying distance between time steps, an interpolated data set is created using the larger data set in the last section.

The interpolation process is done for each of the simulation files separately by generating a sequence of temperature fields with equal distance between their consecutive time steps. The resulting sequence of time steps for every interpolated simulations are the same by giving a start time step (close to the minimum time step), an end time step (close to the maximum time step) and the number of samples (=100) to generate a new evenly spaced time step sequence to interpolated with. In order to retrieve the temperature field at the target time step, the temperature fields at two nearest time steps are searched for  and the target temperature field is generated by interpolating between these two temperature fields.

After the interpolation process, we are able to get an interpolation data set where every simulation has the same sequence of time steps.

The interpolated dataset are also randomly divided in the same way as the limited dataset for each of the three ML architectures in the following subsections.


\subsection{Compression of temperature fields}

The ConvAE used for compressing the temperature fields in this section has the same structure and the same set of hyperparameters as the one trained with the original larger dataset.

In the following figures, some detailed test results from this ConvAE trained with interpolated dataset are presented:

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/larger_dataset_interpolated/ConvAE_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/larger_dataset_interpolated/ConvAE_OverallTesting.png}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/mantle_convection_images/larger_dataset_interpolated/ConvAE_Best.png}
    \caption{Best Case}
    \label{fig:first}
\end{subfigure}
\hfill
\begin{subfigure}{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/mantle_convection_images/larger_dataset_interpolated/ConvAE_Worst.png}
    \caption{Worst Case}
    \label{fig:second}
\end{subfigure}
        
\caption{Best case and worst case using ConvAE}
\label{fig:figures}
\end{figure}

We can observe that the performance of this ConvAE is better than the one trained with the original larger dataset since it has a total loss that is 3 times lower than the one in the last section (0.0005 to 0.0016). This could imply that the interpolated data make the training process of ConvAE easier given the same size of data. 


\subsection{Fully Connected Neural Network (FNN) for Prediction}

The FNN in this section also has the same structure and the same set of hyperparameters as the one trained with the original larger dataset.

The results are presented in the following figures:

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/larger_dataset_interpolated/FNN_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/larger_dataset_interpolated/FNN_OverallTesting.png}
\end{figure}

\begin{figure}[H]
    \caption{Best case original output, original output after ConvAE's compression-decompression, and predicted output of FNN}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset_interpolated/FNN_Best.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case original output, original output after ConvAE's compression-decompression, and predicted output of FNN}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset_interpolated/FNN_Worst.png}
\end{figure}

The above result of this FNN are better than the one trained with the original larger dataset since the loss values are 2 times lower than the one in the last section (0.0005 to 0.0011), which could be partially due to the better performance of the ConvAE.

Again, two animations representing the best case and the worst case when predicting the entire simulation using the first method (use $T1$ from data set $\rightarrow$ get predicted $T2$ $\rightarrow$ use predicted $T2$ $\rightarrow$ get predicted $T3$ $\rightarrow$ ...) are generated.

The following figures show 10\% of the sprites sheets converted from the original GIF animations (Every 10th frame), along with the POD result for the best case and worst case:

\begin{figure}[H]
    \centering
    \caption{Best case animation sheet (Link to this GIF: \url{https://drive.google.com/file/d/10znEe7q_A0rndmuivlbWBH8sZEH6Gv3p/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/larger_dataset_interpolated/FNN_Best_GIF_sheet.png}
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Worst case animation sheet (Link to this GIF: 
    \url{https://drive.google.com/file/d/1vIXrWn6emumszEy3VDArqdenj3FQeVVa/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/larger_dataset_interpolated/FNN_Worst_GIF_sheet.png}
\end{figure}


\begin{figure}[H]
    \caption{Best case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset_interpolated/FNN_Best_POD.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset_interpolated/FNN_Worst_POD.png}
\end{figure}

We can observe that the problem of predicted GIFs moving faster or slower than the actual simulations is now gone. Also, the POD result in the worst case is now closer than the one in the  original simulations. This confirmed that the varying time steps are the cause of the inconsistent GIF speed problem and by fixing this issue using an interpolated dataset, the performance of the FNN is able to be improved.


\subsection{Long short-term memory (LSTM) for Prediction}

The FNN in this section also has the same structure and the same set of hyperparameters as the one trained with the original larger dataset.

The results are presented in the following figures:

\begin{figure}[H]
    \caption{Training loss and Validation loss}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/larger_dataset_interpolated/LSTM_trainingData.png}
\end{figure}

\begin{figure}[H]
    \caption{Overall testing result}
    \includegraphics[scale=0.8]{figures/mantle_convection_images/larger_dataset_interpolated/LSTM_OverallTesting.png}
\end{figure}

\begin{figure}[H]
    \caption{Best case original output, original output after ConvAE's compression-decompression, and predicted output of LSTM}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset_interpolated/LSTM_Best.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case original output, original output after ConvAE's compression-decompression, and predicted output of LSTM}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset_interpolated/LSTM_Worst.png}
\end{figure}

From the above figures, we can see that the loss of the best case and the average loss of this LSTM is now less than the one trained with the  original larger dataset, which means that the interpolation process improves the accuracy when using LSTM as well.

Again, two animations representing the best case and the worst case when predicting the rest of the simulation using the first 50 temperature fields are generated.

The following figures show 20\% of the sprites sheets converted from the original GIF animations (Every 5th frame), along with the POD result for the best case and worst case:

\begin{figure}[H]
    \centering
    \caption{Best case animation sheet (Link to this GIF: \url{https://drive.google.com/file/d/1fNkJVHw3v8WzVz0IKcPfI9rwmwhYygWS/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/larger_dataset_interpolated/LSTM_Best_GIF_sheet.png}
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Worst case animation sheet, (Link to this GIF: 
    \url{https://drive.google.com/file/d/1JbhX4Zznv9YXHZi8IG811495_-YTOq9l/view?usp=sharing})}
    \includegraphics[scale=0.10]{figures/mantle_convection_images/larger_dataset_interpolated/LSTM_Worst_GIF_sheet.png}
\end{figure}


\begin{figure}[H]
    \caption{Best case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset_interpolated/LSTM_Best_POD.png}
\end{figure}

\begin{figure}[H]
    \caption{Worst case POD}
    \includegraphics[scale=0.5]{figures/mantle_convection_images/larger_dataset_interpolated/LSTM_Worst_POD.png}
\end{figure}


We can observe that the problem of predicted GIFs moving faster or slower than the actual simulations is gone as well, which is consistent with our conclusions in the last subsection.


\subsection{Further testing on FNN}

To determine experimentally for how many time steps we can use the trained FNN during a set of S consecutive time steps (e.g., S=2, S=4, or S=8, and then "correct" the time series with the truth coming from the simulator) without loosing track of the transient dynamics (How large can S be without significantly affecting accuracy), further testings extending the two methods in the FNN section are done over the entire interpolated data set using the trained FNN.

To compare against different values of S, POD are applied for each of the generated temperature field sequence to compare the difference of the eigenvalues between the predicted simulations and actual simulations. The data loss for each simulation are computed as well. The result for S = 1, 2, 4, 8, 16, 99 are shown as below (where S=1 is essentially the first method in the FNN section and S=99 is the second method):

\begin{figure}[H]
    \caption{Data Loss for S consecutive time steps}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/further_testings/Data_Loss_table.png}
\end{figure}

\begin{figure}[H]
    \caption{POD difference for S consecutive time steps}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/further_testings/POD_table.png}
\end{figure}

\begin{figure}[H]
    \caption{Relative POD difference for S consecutive time steps}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/further_testings/Relative_POD_table.png}
\end{figure}

\begin{figure}[H]
    \caption{Data Loss / POD result for S consecutive time steps}
    \includegraphics[scale=0.6]{figures/mantle_convection_images/further_testings/Data_loss_POD_division_table.png}
\end{figure}

We can observe the sum of loss and the sum of POD difference tend to have a rapid increase when S is increased from 4 to 8, as well as the standard of deviation of the data loss. In this case, the maximum value of S that is not significantly affecting accuracy should be 4.




