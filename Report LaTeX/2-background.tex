\chapter{Background}\label{chap:background}


\section{Neural Networks: FNNs, CNNs, and LSTMs}

In this section, we introduce some basic concepts about neural networks (NNs) according to a more detailed explanation provided by Bishop. \citep{10.1117_1.2819119} A simple NN usually consists of one input layer, one output layer and one or more hidden layers in between. The nodes inside each layer are called neurons. 

A feed-forward Fully Connected Neural Network (FNN) using linear layers for connection (the term ``fully connected'' means that the neurons in each layer are connected to all neurons in the previous layer and also the following layer) can be represented as a parameterized function \citep{2306.06304}, here denoted $\mathcal{N}(\theta)$, and defined as the chained composition of $n$ affine maps $\Theta_i$ (i.e., $n$ hidden layers) and activation function $g$:

\begin{equation*}
\mathcal{N}(\theta) = \Theta_n \circ g \circ \Theta_{n-1} \circ \ldots \circ g \circ \Theta_1,
\end{equation*}

where $\theta$ represents the set of all trainable parameters. In general, the activation function $g$ can be
different at each layer. However, for simplicity, we use the same activation function for all layers in this study.

The affine maps can be defined as:
\begin{equation*} 
\Theta_i(x) = xA_i^{T} + b_i, \ \mathrm{with} \ i=1,\ldots,n, 
\end{equation*}
where $A_i$ and $b_i$ are the weight matrix and bias vector, respectively, corresponding to the $i$-th hidden layer.

Both $A_i$ and $b_i$ can be optimized through a technique called error backpropagation. Essentially, we first define a loss function to measure the disagreement (error) between the predicted output from the output layer and the actual output from the dataset. The error is then propagated backwards through all the hidden layers using the chain rule to perform differentiation. Eventually, these derivatives of errors with respect to the weights are used to update the trainable parameters ($A_i$ and $b_i$) in each hidden layer. This complete process is called gradient descent. 

By looping over the process of feeding the input data into NN to perform prediction, calculating the loss between the prediction and the actual data and eventually using the loss value to optimize the trainable parameters in each layer, the NN model is able to be adjusted to a state that best fits to the underlying pattern of the provided dataset.

In this study, we use a Machine Learning library called PyTorch to implement the NN architecture, specifying the loss function and optimizer that minimize the loss function (Adam optimizer, in this case, is used throughout the study due to its broader adoption for deep learning) and systematically train and test the performance of the networks.

Apart from FNNs, Convolutional Neural Networks (CNNs) are also one of the most commonly used NNs. They can identify 
spatial patterns in matrix or image input better than the traditional FNN with linear layers. Instead of linear layers, they use convolutional layers that contain specified numbers of trainable filters, each of which is used to enhance or identify a particular feature in the input. Filters are convolved with the input image or the output of the previous layer, the results are summed together along with a trainable bias, and passed through an activation function to produce a feature map. Similar to FNNs, an activation function is also added to introduce non-linearity to the feature map.

In this study, a variation of CNNs is used as a way to compress the size of the input data in the mantle convection problem, which is called Convolutional AutoEncoder (ConvAE). It is constructed as two separate structures that are trained together: an encoder using convolution operation to reduce the size of the original input and output a latent space representation, and a decoder using deconvolution operation to transform the latent space representation back to its original size. By feeding the input into a ConvAE, the dimension of the original high-resolution input can be decreased with the main features captured (some information may be lost during the encoding process nevertheless), thus making it more computationally efficient to work with if we want to feed it into a prediction NN.

Since the dataset in the mantle convection problem is a time sequence with adaptive timestamps, Long Short-Term Memory (LSTM) is used to predict a sequence of output apart from FNN. LSTM's architecture that use a sequence of input recurrently during prediction allows it to handle time-series data more accurately than other networks since it uses a set of inputs from previous time-steps to predict the outputs at the next set of time-steps, thus leading to a potential better result.


\section{Related works on solving geoid and mantle convection using NNs}

Neural networks have increasingly been used in the modelling of geodynamics problems nowadays, in particular, when it comes to geoid and mantle convection simulations. 

For example, Kerl, in his master thesis \citep{kerl2022geoid}, provides a bold attempt at using ML as a low-cost solution to the geoid inverse problem. In this work, two different solutions using a different number of CNNs are compared. He found that the single network solution where a radial viscosity profile is predicted directly from the geoid and density data allows to obtain a smooth, long-wavelength estimate of the Earth's radial viscosity profile. This provides us some implications on using only one NN to tackle the forward problem instead of a solution in which different NNs are used to predict intermediate results to be chained to produce the final result.

As for the mantle convection problem, Agarwal et. al. \citep{10.1093_gji_ggaa234} make use of the FNN architecture to build a surrogate model that can predict the entire time evolution (0-4.5 Gyr) of the 1D temperature profile of a Mars-like planet for a wide range of values of five different parameters, including reference viscosity, activation energy and activation volume of diffusion creep, enrichment factor of heat-producing elements in the crust and initial temperature of the mantle.

In another study that particularly worths highlighting \citep{10.1103_physrevfluids.6.113801}, Agarwal et. al. extend the previously mentioned approach \citep{10.1093_gji_ggaa234}. Instead of predicting the time evolution of 1D laterally-averaged temperature profiles from a large number of 2D simulations, the goal in this work is to predict the full 2D temperature field, since it contains richer information of the structure of the convection.\citep{10.1103_physrevfluids.6.113801} To show that NN techniques can produce reliable parameterized surrogates, they first used ConvAE to compress the size of each temperature field by a factor of 142 and then use FNN and LSTM to predict time series of compressed fields. They discovered that LSTM captures the flow dynamics better than FNN despite the fact that LSTM has a lower mean relative accuracy. Their study provides us some essential insights in solving the forward mantle convection problem using NNs as a low-cost solution, including ConvAE to compress the data and compare the prediction result of two different architectures (FNN and LSTM).

Overall, previous works have explored the usage of Convolutional Neural Networks (CNNs) to solve the inverse geoid problem directly \citep{kerl2022geoid} or FNNs/LSTMs to approximate the 2D forward mantle convention problem \citep{10.1103_physrevfluids.6.113801}. 

In contrast to these works:
\begin{itemize}
    \item We use FNN on a 1D spherically symmetric viscosity model to solve the forward geoid problem as a first step to solve the inverse geoid problem.
    
    \item We aim to produce the complete mantle convection time-series from an initial temperature field, rather than the next time-step out of the previous ones for a given set of parameters of the mantle convection model.
\end{itemize}
