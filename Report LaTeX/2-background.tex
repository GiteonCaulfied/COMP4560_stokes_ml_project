\chapter{Background}\label{chap:background}


\section{Neural Networks: Fully connected, Convolutional and Long Short-Term Memory}

In this section, we introduce some basic concept about neural networks (NNs) according to a more detailed explanation provided by Bishop. \citep{10.1117_1.2819119} A simple NN usually consists of one input layer, one output layer and one or more hidden layers in between. Multiple nodes inside each layers are called neurons. 

A feedforward Fully Connected Neural Network (FNN) using linear layers for connection (the term “fully connected” means that the neurons in each layer have a connection to all neurons in the previous layer and also the following layer) can be represented as a parameterized function \citep{2306.06304}, here denoted $\mathcal{N}(\theta)$, and defined as the chained composition of $n$ affine maps $\Theta_i$ (i.e., $n$ hidden layers) and activation function $g$:

\begin{equation*}
\mathcal{N}(\theta) = \Theta_n \circ g \circ \Theta_{n-1} \circ \ldots \circ g \circ \Theta_1,
\end{equation*}

where $\theta$ represents the set of all trainable parameters.

The affine maps can be defined as:
\begin{equation*} 
\Theta_i(x) = xA_i^{T} + b_i, \ \mathrm{with} \ i=1,\ldots,n, 
\end{equation*}

where $A_i$ and $b_i$ are the weight matrix and bias vector, respectively, corresponding to the $i$-th hidden layer.

Both $A_i$ and $b_i$ are able to be optimized through a technique called error backpropagation, where we first define a loss function to calculate the loss value (error) between the predicted output from the output layer and the actual output from the dataset. The error is then propagated backwards through all the hidden layers using the chain rule to perform differentiation. Eventually, these derivatives of errors with respect to the weights are used to update the learnable parameters ($A_i$ and $b_i$) in each hidden layer. This complete process is called gradient descent. 

By looping over the process of feeding the input data into NN to perform prediction, calculating the loss between the prediction and the actual data and eventually using the loss value to optimize the learnable parameters in each layers, the NN model is able to be adjusted to a state that best fits the underlying pattern of the provided dataset given its current structure.

In this study, we use a ML library called PyTorch to implement the NN architecture, specifying the loss function and optimizer that minimize the loss function (Adam optimizer, in this case, is used throughout the study due to its broader adoption for deep learning) and systematically train and test the performance of the networks.

Apart from FNNs, Convolutional Neural Networks (CNNs) are also one of the most commonly used NNs. They can handle matrix or image input better than the traditional FNN with linear layers. Instead of linear layers, they use convolutional layers that contain specified numbers of trainable filters, each of which is used to enhance or identify a particular feature in the input. Filters are convolved with the input image or the output of the previous layer, and the results are summed together along with a trainable bias and passed through an activation function to produce a feature map. Similar to FNN, activation function is also added to introduce non-linearity to the feature map.

In this study, a variation of CNN is used as a way to compress the size of the input data in the mantle convection problem, which is called Convolutional AutoEncoder (ConvAE). It is constructed as two separate sturctures that are trained together: an encoder using convolution operation to reduce the size of the original input and output a latent space representation, and a decoder using deconvolution operation to transform the latent space representation back to its original size. By feeding the input into a ConvAE, the dimension of the original high-resolution input can be decreased with the main features captured (some information may be lost during the encoding process), thus making it more computationally efficient to work with if we want to feed it into a prediction NN.

Since the dataset in the mantle convection problem is a time sequence with adaptive timestamps, long short-term memory (LSTM) is used to predict a sequence of output apart from FNN. LSTM's architecture that use a sequence of input recurrently during prediction allows it to handle time-series data more accurately than other networks since it uses a set of inputs from previous time-steps to predict the outputs at the next set of time-steps, thus leading to a potential better result.


\section{Related works for solving geoid and mantle convection using Neural Networks}

Neural networks has been increasingly used for studying the geodynamics nowadays, especially when it comes to solving geoid or mantle convection simulation. 

For example, Kerl provide a bold attempt at using ML as a low-cost solution to the geoid inverse problem in his thesis, where two separate solutions using different number of CNNs are compared.\citep{kerl2022geoid} He found that the single network solution where a radial viscosity profile is predicted directly from the geoid and density data allows him to obtain a smooth, long-wavelength estimate of the Earth’s radial viscosity profile. This provides us some implications on using only one NN to solve the inverse problem instead of stacking NNs together.

As for the mantle convection problem, a group of researchers \citep{10.1093_gji_ggaa234} make use of the FNN architecture to build a surrogate model that can predict the entire evolution (0–4.5 Gyr) of the 1D temperature profile of a Mars-like planet for a wide range of values of five different parameters, including reference viscosity, activation energy and activation volume of diffusion creep, enrichment factor of heat-producing elements in the crust and initial temperature of the mantle.

In another study that is particularly worth highlighting, Agarwal and other researchers extend their previous approach \citep{10.1093_gji_ggaa234} of using FNN trained using a large number of 2D simulations to predict the evolution of entire 1D laterally-averaged temperature profile in time for complex models. Instead of predicting 1D temperature field, the full 2D temperature field are predicted since it could contain more information related to the structure of the convection.\citep{10.1103_physrevfluids.6.113801} To show that NN techniques can produce reliable parameterized surrogates, they first use ConvAE to compress the size of each temperature field by a factor of 142 and then use FNN and LSTM to predict the compressed fields. They discovered that LSTM capture the flow dynamics better than FNN despite the fact that LSTM has a lower mean relative accuracy. Their study provides us some essential insights in solving the mantle convection problem by using NNs as a low-cost solution, including using ConvAE to compress the data and compare the prediction result of two different architectures (FNN and LSTM).

Overall, previous works have explored the usage of Convolutional Neural Networks (CNNs) to solve the inverse geoid problem directly \citep{kerl2022geoid} or FNNs/LSTMs to approximate the forward mantle convention problem \citep{10.1103_physrevfluids.6.113801}. 

In contrast to these works:
\begin{itemize}
    \item We use FNN on 1D spherically symmetric viscosity model to solve the forward geoid problem as a first step to solve the inverse geoid problem.
    
    \item We aim to produce the complete mantle convection time-series from an initial temperature field, rather than the next time-step out of the previous ones for a given set of parameters of the mantle convection model.
\end{itemize}
