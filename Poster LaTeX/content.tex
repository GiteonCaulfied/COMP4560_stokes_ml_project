\Block{Introduction}{

\textbf{Motivation}

\begin{itemize}
    \item Earth's mantle, the topmost 3000 km layer, undergoes a process known as mantle convection. A paramount challenge in geosciences is reconstructing the thermochemical evolution of Earth's mantle and its various surface manifestations, where the insights into previous mantle states are imperative.

    \item Therefore, the concept of the inverse problem is introduced to determine a model through gradient-optimisation techniques that aligns most coherently with data derived from partial, imperfect, or noisy measurements, whose predominant strategy is called adjoint method. Nevertheless, this approach is computationally intensive.

    \item The primary motivation behind this research is to curtail computational requirements. This is achieved by exploring the potential of deep learning methods as surrogate models that offer the means to approximate the forward and adjoint problems with significantly reduced computational cost.

    \item As a first attempt in this direction, we have addressed the forward problem associated with two well-established geodynamics problems: the `geoid' problem and the 2D Mantle convection problems.
\end{itemize}



\textbf{Geoid Problem}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/Geoid.png}
    \caption{Geoid and its two related factors.}
\end{figure}

\begin{itemize}
     \item Research shows that when geoid is modelled purely based on density variation near the surface, the result can poorly explain the observed geoid measurements.

     \item Therefore, the possibility of using Earth's viscosity to model geoid is explored in this research.
\end{itemize}

\textbf{Mantle Convection Problem}

\begin{figure}[H]
    \includegraphics[width=\linewidth]{figures/Mantle_Convection_workflow.png}
    \caption{Typical mantle convection workflow.}
\end{figure}

\begin{itemize}
    \item The thermal evolution is modelled by solving numerically the Stokes system of partial differential equations derived from the conservation equations of mass, momentum, and energy, in their simplest form of the Boussinesq approximation. 
\end{itemize}

\textbf{Neural Networks}
\begin{itemize}
    \item Fully Connected Neural Network (FNN)
            \begin{itemize} 
                \item A FNN is a paremeterized function, denoted $\mathcal{N}(\theta)$, which is defined as the chained composition of $n$ affine maps $\Theta_i$ (i.e., $n$ hidden layers) and activation function $g$:
            \begin{equation*}
            \mathcal{N}(\theta) = \Theta_n \circ g \circ \Theta_{n-1} \circ \ldots \circ g \circ \Theta_1,
            \end{equation*}
            where  $\theta$ represents the set of all learnable parameters.
               \item The affine maps are defined as:
            \begin{equation*} \Theta_i(x) = xA_i^{T} + b_i, \ \mathrm{with} \ i=1,\ldots,n, \end{equation*}
            where $A_i$ and $b_i$ are the weight matrix and bias vector, respectively, corresponding to the $i$-th hidden layer.
        \end{itemize}

    \item Convolutional Autoencoders (ConvAE)
        \begin{itemize}
            \item An encoder using convolution operation to reduce the size of the original input field and output a latent space representation.

            \item A decoder using deconvolution operation to transform the latent space representation back to the original size field.
        \end{itemize}
    \item Long short-term memory (LSTM)
        \begin{itemize}
            \item Use a sequence of input recurrently to predict a sequence of output.

            \item Handle time-series data more accurately than other networks.
        \end{itemize}

\end{itemize}

}


\Block{Research Aims}{
\textbf{Geoid Problem}

\begin{itemize}
     \item This research aims to use Neural Networks as a way to forward model the geoid problem, assuming that viscosity varying in the radial direction with depth is the most important factor.

     \item The Earth's viscosity is modelled as a 1D spherically symmetric viscosity model and a geoid surface is computed in terms of spherical harmonics coefficients, which can be used to construct the geoid surface.
\end{itemize}

\textbf{Mantle Convection Problem}

\begin{itemize}
     \item (TODO)
\end{itemize}
}


\Block{Methods}{

\textbf{Geoid Problem}.
\begin{itemize}
    \item Testing on a simplified small dataset (having 1000 pairs of input and output) using a reduced prior such that the perturbations to the output are smaller.

        \begin{itemize}
            \item Input: a vector with 257 values indicating a 1D spherically symmetric viscosity model.

	    \item Output: a vector with 60 values         representing a set of spherical harmonic      coefficients describing the geoid height      on the surface of the Earth.
        \end{itemize}
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/Geoid_Sample_visualization.png}
    \caption{Sample geoid field, where the units of the geoid are in metres and represent values greater or less than some reference value.}
\end{figure}

\begin{itemize}
    \item Using Fully Connected Neural Networks (FNN) for prediction.

    \item Systematically training and testing different FNN architectures.
\end{itemize}

\bigbreak

\textbf{Mantle Convection Problem}
\begin{itemize}

    \item Testing on 3 different datasets, where each dataset is composed of several temperature 
          time-series with 100 timestamps each resulting from numerical simulations 
          with randomly sampled initial conditions.

        \begin{itemize}

        \item Limited dataset: 100 simulations, varying distance between consecutive time steps.

	    \item Larger dataset: 903 simulations,           varying distance between consecutive          time steps.

            \item Interpolated dataset: generated from the Larger dataset, 903 simulations, equal distance between consecutive time steps.
        \end{itemize}
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/temperature_field_example.png}
    \caption{Sample Temperature field.}
\end{figure}
}



\Block{Methods (Continue)}{

\begin{itemize}

    \item Using Convolutional Autoencoders (ConvAE) to compress the data into its latent space representation.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/ConvAE_workflow.png}
    \caption{ConvAE workflow.}
\end{figure}

\begin{itemize}
    \item Given a temperature field in its latent space representation, using Fully Connected Neural Network (FNN) to predict temperature field at the next timestamp.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/FNN_workflow.png}
    \caption{FNN workflow.}
\end{figure}

\begin{itemize}
    \item Two possible ways to predict a complete simulation using FNN:

        \begin{itemize}
            \item use $T1$ from data set $\rightarrow$ get predicted $T2$ $\rightarrow$ use predicted $T2$ $\rightarrow$ get predicted $T3$ $\rightarrow$ ...

            \item use $T1$ from data set $\rightarrow$ get predicted $T2$ $\rightarrow$ use $T2$ from data set $\rightarrow$ get predicted $T3$ $\rightarrow$ ...
        \end{itemize}

    \item Given the first 50 temperature fields from a simulation in its latent space representation, using Long Short-Term Memory (LSTM) to predict the last 50 temperature fields as a sequence.

\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/LSTM_workflow.png}
    \caption{General LSTM structure and the workflow in this research. (Source of the left figure: StackOverflow.)}
\end{figure}
}

\Block{Results and Findings}{

\textbf{Geoid Problem}.

\begin{itemize}
    \item FNN architectures with a total number of 4 hidden layers have the best performance (among those tested)
    when the output data is normalised using a scaler before training and testing.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/Geoid_Best_visualization}
    \caption{Visualization of the most accurate geoid prediction.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/Geoid_Worst_visualization}
    \caption{Visualization of the least accurate geoid prediction.}
\end{figure}


\textbf{Mantle Convection Problem}

\begin{itemize}

    \item Limited Dataset
        \begin{itemize}
            \item ConvAE has low reconstruction error given a latent space size of 6x23x45, which offers an excellent compression factor of 13.

            \item FNN has low loss value when predicting the next temperature field given a total of 3 hidden layers. However, when predicting a complete simulation using FNN:

            \begin{itemize}
                \item output-as-input prediction fails to capture the trend of simulation in its worst case and the prediction result is completely different to the actual simulations.

                \item while the second method mostly matches with the actual output even in its worst case.

            \end{itemize}

            \item LSTM has a higher loss value than FNN, but is able to capture the characteristic of the simulation more precisely.

            \item predicted animations generated by FNN and LSTM are either moving faster or slower than the actual simulations.

        \end{itemize}

    \item Larger Dataset
        \begin{itemize}
            \item Low reconstruction error for ConvAE given the same architecture.

            \item No significant improvement for the prediction result of FNN and LSTM.

            \item Confirmed that the lower accuracy of LSTM is not caused by some potential underfitting problem brought by the limited size of the data.

            \item The problem of the predicted animations having inconsistent speed still exists.

        \end{itemize}


    \item Interpolated Dataset

    \begin{itemize}
            \item Lower reconstruction error is 3 times lower for ConvAE given the same architecture.

            \item Better performance for both FNN and LSTM.

            \item The problem of the predicted animations having inconsistent speed with the actual one is now solved. Confirmed that this problem is caused by the varying distance between consecutive time steps.

    \end{itemize}

\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/FNN_animation_sheet.png}
    \caption{Best case animation sheet for FNN trained with Interpolated Dataset, where each frame consists of 3 temperature fields as a group, representing the ground truth, prediction from the first method (output-as-input looping) and prediction from the second method (single prediction). Predictions from 10 different time steps are presented in this sheet from left to right and top to bottom, including 10, 20, 30, 40, 50, 60, 70, 80, 90, and 100. (see Fig. 4 for colorbar)}
\end{figure}

}

\Block{Results and Findings (Continue)}{

\begin{itemize}
    \item Further Testings on FNN trained with Interpolated Dataset
        \begin{itemize}
            \item The aim is to determine experimentally for how many time steps we can use the trained FNN during a set of S consecutive time steps (e.g., S=2 and then ”correct” the time series with the truth coming from the simulator) without losing track of the transient dynamics (How large can S be without significantly affecting accuracy).

            \item The growth of the loss function (accuracy degradation) with S is remarkably moderate, with only a few outliers deviating moderately from the median.
        \end{itemize}
\end{itemize}

\begin{figure}[H]
    \includegraphics[width=0.8\linewidth]{figures/FNN_boxplot.png}
    \caption{Box Plot for data loss when FNN is used in S consecutive time steps before correction.}
\end{figure}

\begin{figure}[H]
    \includegraphics[width=0.9\linewidth]{figures/FNN_further_testing_sheet.png}
    \caption{Animation sheet when FNN is either not used (ground truth at the first row) or used in S consecutive time steps before correction, where S = 1, 2, 4, 8, 16, and 99 (started from the second row). The time steps, from left to right, are 1, 25, 50, 75, and 100. (see Fig. 4 for colorbar)}
\end{figure}
}

\Block{Conclusion}{
\textbf{Geoid Problem}

\begin{itemize}
     \item We showed that high-dimensional regression algorithms like neural networks can help with the forward modelling of the geoid problem when predicting a set of spherical harmonic coefficients given a reduced dataset with a fairly small number of 1D spherically symmetric viscosity models.
\end{itemize}

\textbf{Mantle Convection Problem}

\begin{itemize}
     \item We use neural networks as surrogate models for mantle convection simulations and found that while the fully connected neural network (FNN) offers a better accuracy and the result has less data loss when predicting a single temperature field, the Long short-term memory (LSTM) is slightly more capable to capture the general characteristics of a complete simulation when predicting a sequence of temperature fields, compared with the "looping" method when predicting a sequence using FNN. 
     
     \item We also found that data set with adaptive time steps between each temperature field could lead to the problem of the predicted time series moving faster or slower than the ground truth, and we solved this issue by using an interpolated data set having same distance between temperature fields instead.

    \item We tested two possible methods for FNN to predict a complete simulation. The first method clearly use much less computation resources (1:99 of the demanding ground truth from numerical simulator when comparing these two method) but suffers from low accuracy.

    \item We found that when FNN is used in S consecutive time steps, the growth of the data loss with S (ranging from 1, 2, 4, 8 to 16) is remarkably moderate, with only a few outliers deviating moderately from the median. This could provide some useful implications for the future research.
\end{itemize}

}


\Block{Future Works}{
\textbf{Geoid Problem}

\begin{itemize}
     \item Future studies may focus on extending the use of neural networks on solving the geoid problem using viscosity models by testing with a more general dataset, since the one used in this research is using a reduced prior such that the perturbations to the output are far smaller.

     \item Future studies could also explore the potential use of neural networks to backward model the geoid problem.
\end{itemize}

\textbf{Mantle Convection Problem}

\begin{itemize}
     \item Future studies may continue to explore the potential use of the trained FNN on a set of S consecutive time steps. If we can replace the fine-grained truth temperature field from the simulator (size is 201x401), which is used to "correct" the predicted time series, with a coarse-grained temperature field (e.g., size is 50x100), the computational demands of modelling mantle convection problem could be further reduced.

     \item Future studies could also focus on improving the performance of LSTM or using less truth temperature fields to predict more temperature fields, rather than sticking to the current ratio of 50:50 for input and output due to technical limitations of PyTorch.

     \item The outliers in Figure 11 could be further investigated to see whether a common pattern can be identified.

     \item More complex physics (e.g., non-linear constitutive laws) could be considered in the Mantle convection model.

     \item Investigating to which extent the current surrogate forward models are accurate enough to end up with sensible, application experts-certified solutions to the inverse mantle convection problem.
\end{itemize}
}

\Block{Literature}{
\begin{itemize}
\item Agarwal, S.; Tosi, N.; Breuer, D.; Padovan, S.; Kessel, P.; and Montavon, G., 2020. A machine-learning-based surrogate model of mars’ thermal evolution.
Geophysical Journal International, 222, 3 (may 2020), 1656–1670. doi:10.1093/gji/ggaa234. https://doi.org/10.1093/gji/ggaa234.

\item Agarwal, S.; Tosi, N.; Kessel, P.; Breuer, D.; and Montavon, G., 2021. Deep learning for surrogate modeling of two-dimensional mantle convection. Physical
Review Fluids, 6, 11 (nov 2021). doi:10.1103/physrevf luids.6.113801. https://doi.org/10.1103/physrevfluids.6.113801.

\item Kerl, J., 2022. Geoid Inversion For Mantle Viscosity With Convolutional Neural Net-
works. Master thesis.
\end{itemize}
}

\Block{Acknowledgements}{
This work was supported by computational resources provided by the Australian Government through the National Computational Infrastructure (NCI) under the ANU Merit Allocation Scheme.
}